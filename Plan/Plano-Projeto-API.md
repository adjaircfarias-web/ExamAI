# üìã Plano de Projeto: API de Extra√ß√£o de Exames M√©dicos

**Projeto:** MedicalExamExtractor API  
**Data de Cria√ß√£o:** 29/01/2026  
**Vers√£o:** 1.1  
**Autor:** Adjair Farias (com Clawdex üîç)

---

## üìñ Vis√£o Geral

Sistema API REST para extra√ß√£o autom√°tica de dados estruturados de laudos m√©dicos em m√∫ltiplos formatos (PDF, Word, Excel), utilizando AI Agents com LLM local (Ollama), armazenamento em PostgreSQL, e endpoints para consulta dos resultados.

### **Objetivos**

1. ‚úÖ Receber uploads de documentos m√©dicos (PDF, DOCX, XLSX)
2. ‚úÖ Extrair dados estruturados usando AI Agents
3. ‚úÖ Armazenar em PostgreSQL normalizado
4. ‚úÖ Fornecer endpoints REST para consulta
5. ‚úÖ Manter privacidade (LLM local, dados n√£o saem do servidor)

### **Escopo**

| Inclu√≠do | N√£o Inclu√≠do (v1) |
|----------|-------------------|
| Upload de PDF/Word/Excel | Autentica√ß√£o/Autoriza√ß√£o |
| Extra√ß√£o com Ollama (local) | Dashboard web |
| Armazenamento PostgreSQL | Integra√ß√£o HL7/FHIR |
| Endpoints de consulta | OCR para manuscritos |
| Logs e observabilidade | Machine Learning avan√ßado |

---

## üèóÔ∏è Arquitetura do Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     Cliente (Postman/App)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ HTTP/REST
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  API Gateway (.NET 10)                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Upload      ‚îÇ  ‚îÇ  Query       ‚îÇ  ‚îÇ  Health      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Controller  ‚îÇ  ‚îÇ  Controller  ‚îÇ  ‚îÇ  Controller  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                  ‚îÇ
          ‚ñº                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Application Layer (Services)               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ         MedicalExamPipeline (Orquestrador)         ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ     ‚îÇ      ‚îÇ          ‚îÇ           ‚îÇ          ‚îÇ          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇDoc  ‚îÇ‚îÇOCR   ‚îÇ  ‚îÇExtract ‚îÇ  ‚îÇValidat‚îÇ‚îÇNorm   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇParse‚îÇ‚îÇAgent ‚îÇ  ‚îÇAgent   ‚îÇ  ‚îÇAgent  ‚îÇ‚îÇAgent  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   Ollama   ‚îÇ
                    ‚îÇ(Llama 3.1) ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Data Layer (Repository)                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ         ExamRepository (EF Core)                 ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ  PostgreSQL  ‚îÇ
                  ‚îÇ   Database   ‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ü§ñ Integra√ß√£o com Ollama 3.1 Local - Guia Completo

### **1. O que √© Ollama?**

Ollama √© uma ferramenta que permite rodar **Large Language Models (LLMs) localmente** no seu computador, sem necessidade de APIs externas. Ideal para:

- ‚úÖ **Privacidade total** (dados n√£o saem do servidor)
- ‚úÖ **Custo zero** por infer√™ncia
- ‚úÖ **Baixa lat√™ncia** (sem round-trip para cloud)
- ‚úÖ **Offline-first** (funciona sem internet)

---

### **2. Instala√ß√£o do Ollama**

#### **Windows**

```powershell
# Op√ß√£o 1: Instalador oficial
# Baixar de: https://ollama.com/download/windows
# Executar o instalador

# Op√ß√£o 2: Winget
winget install Ollama.Ollama

# Verificar instala√ß√£o
ollama --version
# Output esperado: ollama version 0.x.x
```

#### **Linux**

```bash
# Instala√ß√£o via script oficial
curl -fsSL https://ollama.com/install.sh | sh

# Verificar
ollama --version
```

#### **macOS**

```bash
# Baixar de: https://ollama.com/download/mac
# Ou via Homebrew
brew install ollama

# Verificar
ollama --version
```

---

### **3. Download e Setup de Modelos**

#### **Llama 3.1 - Variantes Dispon√≠veis**

```bash
# Llama 3.1 8B (Recomendado para come√ßar)
# Requer: ~5GB VRAM, ~8GB RAM
ollama pull llama3.1:8b

# Llama 3.1 70B (Melhor qualidade)
# Requer: ~40GB VRAM, ~64GB RAM
ollama pull llama3.1:70b

# Llama 3.1 8B Instruct (Otimizado para instru√ß√µes)
ollama pull llama3.1:8b-instruct

# Verificar modelos instalados
ollama list
```

**Output esperado:**
```
NAME                ID              SIZE    MODIFIED
llama3.1:8b         abc123def456    4.7 GB  2 minutes ago
```

#### **Testar o Modelo**

```bash
# Modo interativo
ollama run llama3.1:8b

>>> Ol√°, voc√™ entende portugu√™s?
Sim, eu entendo portugu√™s! Como posso ajud√°-lo?

>>> /bye  # Para sair
```

#### **Verificar API REST**

```bash
# Ollama exp√µe API REST em http://localhost:11434
curl http://localhost:11434/api/tags

# Response:
{
  "models": [
    {
      "name": "llama3.1:8b",
      "size": 4661224448,
      "digest": "abc123...",
      "modified_at": "2026-01-29T12:00:00Z"
    }
  ]
}
```

---

### **4. Integra√ß√£o no .NET 10**

#### **Pacotes NuGet**

```bash
# Adicionar pacote oficial Microsoft.Extensions.AI
dotnet add package Microsoft.Extensions.AI --prerelease
dotnet add package Microsoft.Extensions.AI.Ollama --prerelease

# Verificar vers√µes instaladas
dotnet list package
```

#### **appsettings.json**

```json
{
  "Ollama": {
    "Url": "http://localhost:11434",
    "Model": "llama3.1:8b",
    "Temperature": 0.1,
    "MaxTokens": 4096,
    "TimeoutSeconds": 60
  },
  "ConnectionStrings": {
    "DefaultConnection": "Host=localhost;Database=medicalexams;Username=postgres;Password=postgres123"
  },
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft.Extensions.AI": "Debug"
    }
  }
}
```

#### **Configura√ß√£o no Program.cs**

```csharp
using Microsoft.Extensions.AI;
using Serilog;

var builder = WebApplication.CreateBuilder(args);

// ===================================================
// Configurar Serilog (Logging)
// ===================================================
Log.Logger = new LoggerConfiguration()
    .ReadFrom.Configuration(builder.Configuration)
    .Enrich.FromLogContext()
    .WriteTo.Console()
    .WriteTo.File("logs/api-.txt", rollingInterval: RollingInterval.Day)
    .CreateLogger();

builder.Host.UseSerilog();

// ===================================================
// Configurar Ollama IChatClient
// ===================================================
builder.Services.AddSingleton<IChatClient>(sp =>
{
    var config = sp.GetRequiredService<IConfiguration>();
    var logger = sp.GetRequiredService<ILogger<Program>>();
    
    var ollamaUrl = config["Ollama:Url"] ?? "http://localhost:11434";
    var model = config["Ollama:Model"] ?? "llama3.1:8b";
    
    logger.LogInformation("Configuring Ollama client: {Url}, Model: {Model}", ollamaUrl, model);

    try
    {
        var client = new OllamaChatClient(new Uri(ollamaUrl), model)
            .AsBuilder()
            .UseLogging(sp.GetRequiredService<ILoggerFactory>())
            .Build();

        logger.LogInformation("Ollama client configured successfully");
        return client;
    }
    catch (Exception ex)
    {
        logger.LogError(ex, "Failed to configure Ollama client");
        throw;
    }
});

// ===================================================
// Registrar Agents e Services
// ===================================================
builder.Services.AddScoped<DocumentParserAgent>();
builder.Services.AddScoped<ExtractionAgent>();
builder.Services.AddScoped<ValidationAgent>();
builder.Services.AddScoped<NormalizationAgent>();
builder.Services.AddScoped<MedicalExamPipeline>();

// ===================================================
// Database (PostgreSQL + EF Core)
// ===================================================
builder.Services.AddDbContext<AppDbContext>(options =>
    options.UseNpgsql(builder.Configuration.GetConnectionString("DefaultConnection")));

builder.Services.AddScoped<IExamRepository, ExamRepository>();

// ===================================================
// Controllers e Swagger
// ===================================================
builder.Services.AddControllers();
builder.Services.AddEndpointsApiExplorer();
builder.Services.AddSwaggerGen(c =>
{
    c.SwaggerDoc("v1", new() 
    { 
        Title = "Medical Exam Extractor API", 
        Version = "v1",
        Description = "API para extra√ß√£o autom√°tica de dados de exames m√©dicos"
    });
});

var app = builder.Build();

// ===================================================
// Middleware
// ===================================================
if (app.Environment.IsDevelopment())
{
    app.UseSwagger();
    app.UseSwaggerUI();
}

app.UseHttpsRedirection();
app.UseAuthorization();
app.MapControllers();

// ===================================================
// Health Check do Ollama
// ===================================================
app.MapGet("/health/ollama", async (IChatClient chatClient) =>
{
    try
    {
        var response = await chatClient.CompleteAsync("ping", new ChatOptions
        {
            MaxTokens = 10,
            Temperature = 0
        });
        
        return Results.Ok(new 
        { 
            status = "healthy", 
            model = "llama3.1:8b",
            response = response.Message.Text
        });
    }
    catch (Exception ex)
    {
        return Results.Problem(
            title: "Ollama Unhealthy",
            detail: ex.Message,
            statusCode: 503
        );
    }
});

app.Run();
```

---

### **5. Implementa√ß√£o do ExtractionAgent**

```csharp
using Microsoft.Extensions.AI;
using System.Text.Json;

namespace MedicalExamExtractor.Application.Agents;

public class ExtractionAgent
{
    private readonly IChatClient _llm;
    private readonly ILogger<ExtractionAgent> _logger;
    private readonly IConfiguration _config;

    public ExtractionAgent(
        IChatClient llm, 
        ILogger<ExtractionAgent> logger,
        IConfiguration config)
    {
        _llm = llm;
        _logger = logger;
        _config = config;
    }

    public async Task<ExamResult> ExtractStructuredDataAsync(
        string documentText,
        CancellationToken cancellationToken = default)
    {
        _logger.LogInformation("Starting extraction from document ({Length} chars)", 
            documentText.Length);

        var systemPrompt = BuildSystemPrompt();
        var userPrompt = BuildUserPrompt(documentText);

        var messages = new List<ChatMessage>
        {
            new(ChatRole.System, systemPrompt),
            new(ChatRole.User, userPrompt)
        };

        var options = new ChatOptions
        {
            Temperature = _config.GetValue<float>("Ollama:Temperature", 0.1f),
            MaxTokens = _config.GetValue<int>("Ollama:MaxTokens", 4096),
            StopSequences = new[] { "=== FIM ===" }
        };

        try
        {
            _logger.LogDebug("Calling Ollama with {MessageCount} messages", messages.Count);
            
            var sw = System.Diagnostics.Stopwatch.StartNew();
            var response = await _llm.CompleteAsync(messages, options, cancellationToken);
            sw.Stop();
            
            _logger.LogInformation("Ollama responded in {ElapsedMs}ms", sw.ElapsedMilliseconds);
            _logger.LogDebug("Raw response: {Response}", response.Message.Text);

            var jsonText = CleanJsonResponse(response.Message.Text);
            
            var result = JsonSerializer.Deserialize<ExamResult>(jsonText,
                new JsonSerializerOptions 
                { 
                    PropertyNameCaseInsensitive = true,
                    PropertyNamingPolicy = JsonNamingPolicy.SnakeCaseLower
                });

            if (result == null)
                throw new InvalidOperationException("Deserialization returned null");

            _logger.LogInformation("Successfully extracted {ExamCount} exams", 
                result.Exames?.Count ?? 0);

            return result;
        }
        catch (JsonException ex)
        {
            _logger.LogError(ex, "Failed to parse JSON from LLM response");
            throw new InvalidOperationException("LLM returned invalid JSON", ex);
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Extraction failed");
            throw;
        }
    }

    private string BuildSystemPrompt()
    {
        return @"
Voc√™ √© um especialista em an√°lise de exames cl√≠nicos brasileiros.
Sua tarefa √© extrair TODOS os resultados de exames m√©dicos de documentos e retornar em formato JSON estruturado.

REGRAS OBRIGAT√ìRIAS:
1. Normalize nomes de exames: 'Col. Total' ‚Üí 'Colesterol Total', 'Glicemia Jejum' ‚Üí 'Glicemia em Jejum'
2. Extraia valores num√©ricos com suas unidades (mg/dL, g/dL, %, etc.)
3. Identifique valores de refer√™ncia quando dispon√≠veis (m√≠n/m√°x)
4. Classifique status baseado em refer√™ncias: 'normal', 'baixo', 'alto', 'cr√≠tico'
5. SEMPRE retorne JSON v√°lido (sem markdown, sem c√≥digo)
6. Se n√£o encontrar dados, retorne arrays vazios (nunca null)
7. Datas no formato ISO 8601: yyyy-MM-dd
8. Valores num√©ricos como n√∫meros (n√£o strings)

TIPOS DE EXAMES COMUNS:
- Lipidograma: Colesterol Total, HDL, LDL, VLDL, Triglicer√≠deos
- Glicemia: Glicemia em Jejum, Hemoglobina Glicada (HbA1c)
- Hemograma: Hem√°cias, Leuc√≥citos, Plaquetas, Hemoglobina, Hemat√≥crito
- Fun√ß√£o Renal: Ureia, Creatinina, √Åcido √örico
- Fun√ß√£o Hep√°tica: TGO (AST), TGP (ALT), Gama GT, Bilirrubinas

FORMATO DE SA√çDA (JSON puro):
{
  ""paciente"": {
    ""nome"": ""string ou null"",
    ""data_nascimento"": ""yyyy-MM-dd ou null"",
    ""data_coleta"": ""yyyy-MM-dd ou null"",
    ""medico_solicitante"": ""string ou null""
  },
  ""exames"": [
    {
      ""tipo"": ""Colesterol Total"",
      ""valor"": 200.5,
      ""unidade"": ""mg/dL"",
      ""referencia_min"": 0,
      ""referencia_max"": 200,
      ""status"": ""normal"",
      ""observacoes"": null
    }
  ]
}
".Trim();
    }

    private string BuildUserPrompt(string documentText)
    {
        return $@"
Analise este laudo m√©dico e extraia os dados estruturados:

=== IN√çCIO DO DOCUMENTO ===
{documentText}
=== FIM DO DOCUMENTO ===

IMPORTANTE: Retorne APENAS o JSON (sem ```json, sem explica√ß√µes).
".Trim();
    }

    private static string CleanJsonResponse(string response)
    {
        // Remove markdown code blocks se presentes
        response = response.Trim();
        
        if (response.StartsWith("```json"))
            response = response["```json".Length..];
        else if (response.StartsWith("```"))
            response = response[3..];
        
        if (response.EndsWith("```"))
            response = response[..^3];
        
        return response.Trim();
    }
}

// ===================================================
// DTOs
// ===================================================

public record ExamResult(
    PatientInfo Paciente,
    List<ExamItem> Exames
);

public record PatientInfo(
    string? Nome,
    DateTime? DataNascimento,
    DateTime? DataColeta,
    string? MedicoSolicitante
);

public record ExamItem(
    string Tipo,
    decimal Valor,
    string Unidade,
    decimal? ReferenciaMin,
    decimal? ReferenciaMax,
    string Status,
    string? Observacoes
);
```

---

### **6. Configura√ß√£o Avan√ßada do Ollama**

#### **Modelfile Customizado (Opcional)**

Se quiser ajustar par√¢metros do modelo:

```dockerfile
# Criar arquivo: Modelfile
FROM llama3.1:8b

# Temperature (0.0 = determin√≠stico, 1.0 = criativo)
PARAMETER temperature 0.1

# Top-p (nucleus sampling)
PARAMETER top_p 0.9

# Top-k
PARAMETER top_k 40

# Repeat penalty (evitar repeti√ß√µes)
PARAMETER repeat_penalty 1.1

# Contexto m√°ximo (tokens)
PARAMETER num_ctx 4096

# System prompt padr√£o
SYSTEM """
Voc√™ √© um assistente especializado em an√°lise de documentos m√©dicos.
Sempre retorne respostas em formato JSON estruturado.
"""
```

**Criar modelo customizado:**
```bash
ollama create medical-llama -f Modelfile
ollama run medical-llama
```

**Usar no .NET:**
```csharp
var client = new OllamaChatClient(new Uri(ollamaUrl), "medical-llama");
```

---

### **7. Monitoramento e Troubleshooting**

#### **Logs do Ollama**

```bash
# Windows: logs em
%USERPROFILE%\.ollama\logs\server.log

# Linux/Mac:
~/.ollama/logs/server.log

# Ver logs em tempo real
tail -f ~/.ollama/logs/server.log
```

#### **M√©tricas de Performance**

```csharp
public class OllamaMetricsMiddleware
{
    private readonly IChatClient _llm;
    private readonly ILogger<OllamaMetricsMiddleware> _logger;

    public async Task<ChatCompletion> CallWithMetricsAsync(
        List<ChatMessage> messages,
        ChatOptions options)
    {
        var sw = Stopwatch.StartNew();
        var inputTokens = EstimateTokens(messages);

        try
        {
            var response = await _llm.CompleteAsync(messages, options);
            sw.Stop();

            var outputTokens = EstimateTokens(response.Message.Text);
            var tokensPerSecond = (inputTokens + outputTokens) / (sw.ElapsedMilliseconds / 1000.0);

            _logger.LogInformation(
                "Ollama metrics: Duration={DurationMs}ms, " +
                "InputTokens={InputTokens}, OutputTokens={OutputTokens}, " +
                "Speed={Speed:F1} tokens/s",
                sw.ElapsedMilliseconds,
                inputTokens,
                outputTokens,
                tokensPerSecond
            );

            return response;
        }
        catch (Exception ex)
        {
            sw.Stop();
            _logger.LogError(ex, "Ollama call failed after {DurationMs}ms", 
                sw.ElapsedMilliseconds);
            throw;
        }
    }

    private int EstimateTokens(string text) => text.Length / 4; // Rough estimate
    private int EstimateTokens(List<ChatMessage> messages) =>
        messages.Sum(m => EstimateTokens(m.Text ?? ""));
}
```

#### **Health Check Avan√ßado**

```csharp
[ApiController]
[Route("api/[controller]")]
public class HealthController : ControllerBase
{
    private readonly IChatClient _llm;
    private readonly ILogger<HealthController> _logger;

    [HttpGet("ollama")]
    public async Task<IActionResult> CheckOllama()
    {
        var sw = Stopwatch.StartNew();
        
        try
        {
            var response = await _llm.CompleteAsync(
                "Responda apenas: OK",
                new ChatOptions
                {
                    MaxTokens = 10,
                    Temperature = 0
                }
            );
            sw.Stop();

            return Ok(new
            {
                status = "healthy",
                model = "llama3.1:8b",
                responseTimeMs = sw.ElapsedMilliseconds,
                response = response.Message.Text
            });
        }
        catch (HttpRequestException ex)
        {
            _logger.LogError(ex, "Ollama connection failed");
            return StatusCode(503, new
            {
                status = "unhealthy",
                error = "Cannot connect to Ollama service",
                details = ex.Message
            });
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Ollama health check failed");
            return StatusCode(500, new
            {
                status = "unhealthy",
                error = ex.Message
            });
        }
    }
}
```

---

### **8. Troubleshooting Comum**

| Problema | Causa | Solu√ß√£o |
|----------|-------|---------|
| **Connection refused** | Ollama n√£o est√° rodando | `ollama serve` ou reiniciar servi√ßo |
| **Model not found** | Modelo n√£o baixado | `ollama pull llama3.1:8b` |
| **Out of memory** | GPU/RAM insuficiente | Usar modelo menor (3B) ou aumentar hardware |
| **Slow inference** | CPU-only mode | Instalar drivers CUDA/ROCm para usar GPU |
| **Invalid JSON** | Prompt mal formatado | Ajustar system prompt, adicionar exemplos |
| **Timeout** | Documento muito grande | Aumentar `TimeoutSeconds`, chunking de texto |

#### **Verificar se GPU est√° sendo usada**

```bash
# NVIDIA
nvidia-smi

# Ver uso durante infer√™ncia
watch -n 1 nvidia-smi

# Ollama detecta automaticamente GPUs
ollama run llama3.1:8b
# Deve mostrar: "using GPU: NVIDIA GeForce RTX..."
```

#### **For√ßar CPU-only (se GPU n√£o funcionar)**

```bash
# Windows
$env:OLLAMA_NUM_GPU=0
ollama serve

# Linux/Mac
OLLAMA_NUM_GPU=0 ollama serve
```

---

### **9. Comparativo de Modelos**

| Modelo | Tamanho | VRAM | Precis√£o | Velocidade | Portugu√™s |
|--------|---------|------|----------|------------|-----------|
| **llama3.1:8b** | 4.7 GB | ~6 GB | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ |
| **llama3.1:70b** | 40 GB | ~42 GB | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ | ‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ |
| **qwen2.5:14b** | 8.5 GB | ~10 GB | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ |
| **mistral:7b** | 4.1 GB | ~5 GB | ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ | ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ |
| **phi3:medium** | 7.6 GB | ~9 GB | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ | ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ |

**Recomenda√ß√£o para o projeto:**
- **Desenvolvimento/Testes:** `llama3.1:8b` (r√°pido, bom equil√≠brio)
- **Produ√ß√£o (qualidade):** `qwen2.5:14b` (melhor para portugu√™s + JSON)
- **Produ√ß√£o (velocidade):** `llama3.1:8b-instruct`

---

### **10. Otimiza√ß√µes de Performance**

#### **Cache de Respostas**

```csharp
public class CachedExtractionAgent
{
    private readonly ExtractionAgent _agent;
    private readonly IMemoryCache _cache;

    public async Task<ExamResult> ExtractWithCacheAsync(string documentText)
    {
        var hash = ComputeSha256(documentText);
        
        if (_cache.TryGetValue(hash, out ExamResult? cached))
        {
            _logger.LogInformation("Cache HIT for document {Hash}", hash);
            return cached!;
        }

        _logger.LogInformation("Cache MISS for document {Hash}", hash);
        var result = await _agent.ExtractStructuredDataAsync(documentText);
        
        _cache.Set(hash, result, TimeSpan.FromHours(24));
        return result;
    }

    private string ComputeSha256(string text)
    {
        using var sha256 = SHA256.Create();
        var bytes = Encoding.UTF8.GetBytes(text);
        var hash = sha256.ComputeHash(bytes);
        return Convert.ToHexString(hash);
    }
}
```

#### **Processamento em Lote**

```csharp
public async Task<List<ExamResult>> ExtractBatchAsync(
    List<string> documents,
    int maxParallel = 3)
{
    var semaphore = new SemaphoreSlim(maxParallel);
    var tasks = documents.Select(async doc =>
    {
        await semaphore.WaitAsync();
        try
        {
            return await _agent.ExtractStructuredDataAsync(doc);
        }
        finally
        {
            semaphore.Release();
        }
    });

    return (await Task.WhenAll(tasks)).ToList();
}
```

---

### **11. Fallback para Cloud (H√≠brido)**

```csharp
public class HybridExtractionAgent
{
    private readonly IChatClient _localLlm;   // Ollama
    private readonly IChatClient _cloudLlm;   // OpenAI GPT-4
    private readonly ILogger _logger;

    public async Task<ExamResult> ExtractAsync(
        string text,
        bool forceCloud = false)
    {
        if (forceCloud)
        {
            _logger.LogInformation("Using cloud LLM (forced)");
            return await ExtractWithLlmAsync(_cloudLlm, text);
        }

        try
        {
            _logger.LogInformation("Trying local LLM first");
            return await ExtractWithLlmAsync(_localLlm, text);
        }
        catch (Exception ex)
        {
            _logger.LogWarning(ex, "Local LLM failed, falling back to cloud");
            return await ExtractWithLlmAsync(_cloudLlm, text);
        }
    }

    private async Task<ExamResult> ExtractWithLlmAsync(
        IChatClient llm,
        string text)
    {
        // L√≥gica compartilhada de extra√ß√£o
        var response = await llm.CompleteAsync(BuildPrompt(text));
        return ParseResponse(response);
    }
}
```

---

### **12. Docker Compose com Ollama**

```yaml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "5000:8080"
    environment:
      - Ollama__Url=http://ollama:11434
      - Ollama__Model=llama3.1:8b
      - ConnectionStrings__DefaultConnection=Host=postgres;Database=medicalexams;Username=postgres;Password=postgres123
    depends_on:
      - postgres
      - ollama

  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: medicalexams
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres123
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    # Para usar GPU no Docker (NVIDIA)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: serve

volumes:
  postgres_data:
  ollama_data:
```

**Inicializar:**
```bash
docker-compose up -d

# Ver logs do Ollama
docker-compose logs -f ollama

# Testar
curl http://localhost:11434/api/tags
```

---

## üóÑÔ∏è Modelagem do Banco de Dados (PostgreSQL)

### **Diagrama ER (Entidade-Relacionamento)**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     pacientes       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ id (PK)             ‚îÇ
‚îÇ nome                ‚îÇ
‚îÇ data_nascimento     ‚îÇ
‚îÇ cpf (UNIQUE)        ‚îÇ
‚îÇ created_at          ‚îÇ
‚îÇ updated_at          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚îÇ 1:N
           ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     documentos              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ id (PK)                     ‚îÇ
‚îÇ paciente_id (FK)            ‚îÇ
‚îÇ nome_arquivo                ‚îÇ
‚îÇ tipo_arquivo                ‚îÇ
‚îÇ tamanho_bytes               ‚îÇ
‚îÇ hash_sha256                 ‚îÇ
‚îÇ data_upload                 ‚îÇ
‚îÇ status_processamento        ‚îÇ
‚îÇ erro_processamento          ‚îÇ
‚îÇ created_at                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚îÇ 1:N
           ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     exames                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ id (PK)                     ‚îÇ
‚îÇ documento_id (FK)           ‚îÇ
‚îÇ tipo_exame_id (FK)          ‚îÇ
‚îÇ data_coleta                 ‚îÇ
‚îÇ medico_solicitante          ‚îÇ
‚îÇ laboratorio                 ‚îÇ
‚îÇ created_at                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚îÇ 1:N
           ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   resultados_exame          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ id (PK)                     ‚îÇ
‚îÇ exame_id (FK)               ‚îÇ
‚îÇ parametro                   ‚îÇ
‚îÇ valor_numerico              ‚îÇ
‚îÇ valor_texto                 ‚îÇ
‚îÇ unidade                     ‚îÇ
‚îÇ referencia_min              ‚îÇ
‚îÇ referencia_max              ‚îÇ
‚îÇ status                      ‚îÇ
‚îÇ observacoes                 ‚îÇ
‚îÇ created_at                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   tipos_exame       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ id (PK)             ‚îÇ
‚îÇ nome                ‚îÇ
‚îÇ descricao           ‚îÇ
‚îÇ categoria           ‚îÇ
‚îÇ created_at          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### **Scripts SQL de Cria√ß√£o**

```sql
-- Tabela de Pacientes
CREATE TABLE pacientes (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    nome VARCHAR(255) NOT NULL,
    data_nascimento DATE,
    cpf VARCHAR(11) UNIQUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_pacientes_cpf ON pacientes(cpf);
CREATE INDEX idx_pacientes_nome ON pacientes(nome);

-- Tabela de Documentos Carregados
CREATE TABLE documentos (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    paciente_id UUID REFERENCES pacientes(id) ON DELETE CASCADE,
    nome_arquivo VARCHAR(500) NOT NULL,
    tipo_arquivo VARCHAR(50) NOT NULL,
    tamanho_bytes BIGINT NOT NULL,
    hash_sha256 VARCHAR(64) NOT NULL,
    data_upload TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    status_processamento VARCHAR(50) NOT NULL DEFAULT 'pending',
    erro_processamento TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_documentos_paciente ON documentos(paciente_id);
CREATE INDEX idx_documentos_hash ON documentos(hash_sha256);
CREATE INDEX idx_documentos_status ON documentos(status_processamento);

-- Tabela de Tipos de Exame (Cat√°logo)
CREATE TABLE tipos_exame (
    id SERIAL PRIMARY KEY,
    nome VARCHAR(255) NOT NULL UNIQUE,
    descricao TEXT,
    categoria VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_tipos_exame_categoria ON tipos_exame(categoria);

-- Inserir tipos comuns
INSERT INTO tipos_exame (nome, categoria) VALUES
    ('Hemograma Completo', 'Hematologia'),
    ('Glicemia', 'Bioqu√≠mica'),
    ('Colesterol Total', 'Lipidograma'),
    ('HDL', 'Lipidograma'),
    ('LDL', 'Lipidograma'),
    ('Triglicer√≠deos', 'Lipidograma'),
    ('Ureia', 'Fun√ß√£o Renal'),
    ('Creatinina', 'Fun√ß√£o Renal'),
    ('TGO/AST', 'Fun√ß√£o Hep√°tica'),
    ('TGP/ALT', 'Fun√ß√£o Hep√°tica');

-- Tabela de Exames
CREATE TABLE exames (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    documento_id UUID NOT NULL REFERENCES documentos(id) ON DELETE CASCADE,
    tipo_exame_id INTEGER REFERENCES tipos_exame(id),
    data_coleta DATE,
    medico_solicitante VARCHAR(255),
    laboratorio VARCHAR(255),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_exames_documento ON exames(documento_id);
CREATE INDEX idx_exames_tipo ON exames(tipo_exame_id);
CREATE INDEX idx_exames_data_coleta ON exames(data_coleta);

-- Tabela de Resultados de Exame
CREATE TABLE resultados_exame (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    exame_id UUID NOT NULL REFERENCES exames(id) ON DELETE CASCADE,
    parametro VARCHAR(255) NOT NULL,
    valor_numerico DECIMAL(18, 4),
    valor_texto TEXT,
    unidade VARCHAR(50),
    referencia_min DECIMAL(18, 4),
    referencia_max DECIMAL(18, 4),
    status VARCHAR(50),
    observacoes TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_resultados_exame ON resultados_exame(exame_id);
CREATE INDEX idx_resultados_parametro ON resultados_exame(parametro);
CREATE INDEX idx_resultados_status ON resultados_exame(status);

-- Trigger para atualizar updated_at
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER update_pacientes_updated_at
    BEFORE UPDATE ON pacientes
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();
```

---

## üìÅ Estrutura do Projeto

```
MedicalExamExtractor/
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ MedicalExamExtractor.Api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Controllers/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ExamsController.cs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ PacientesController.cs
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ HealthController.cs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Middleware/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ErrorHandlingMiddleware.cs
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ RequestLoggingMiddleware.cs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Program.cs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ appsettings.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ appsettings.Development.json
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ MedicalExamExtractor.Application/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Services/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MedicalExamPipeline.cs
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ExamQueryService.cs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Agents/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DocumentParserAgent.cs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ OcrAgent.cs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ExtractionAgent.cs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ValidationAgent.cs
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ NormalizationAgent.cs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ DTOs/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ ExamUploadDto.cs
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ ExamResultDto.cs
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ QueryResultDto.cs
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ MedicalExamExtractor.Domain/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Entities/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Paciente.cs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Documento.cs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Exame.cs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ResultadoExame.cs
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ TipoExame.cs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ValueObjects/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Cpf.cs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Interfaces/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ IExamRepository.cs
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ MedicalExamExtractor.Infrastructure/
‚îÇ       ‚îú‚îÄ‚îÄ Data/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ AppDbContext.cs
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ Migrations/
‚îÇ       ‚îú‚îÄ‚îÄ Repositories/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ ExamRepository.cs
‚îÇ       ‚îî‚îÄ‚îÄ Parsers/
‚îÇ           ‚îú‚îÄ‚îÄ PdfParser.cs
‚îÇ           ‚îú‚îÄ‚îÄ WordParser.cs
‚îÇ           ‚îî‚îÄ‚îÄ ExcelParser.cs
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ MedicalExamExtractor.Tests/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Integration/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Unit/
‚îÇ   ‚îî‚îÄ‚îÄ MedicalExamExtractor.Api.Tests/
‚îÇ
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ API.md
‚îÇ   ‚îú‚îÄ‚îÄ DATABASE.md
‚îÇ   ‚îî‚îÄ‚îÄ DEPLOYMENT.md
‚îÇ
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ MedicalExamExtractor.sln
```

---

## üîå Endpoints da API

### **1. Upload de Documentos**

#### `POST /api/exams/upload`

**Request:**
```http
POST /api/exams/upload
Content-Type: multipart/form-data

{
  "file": [binary],
  "cpf": "12345678900",
  "nomePaciente": "Jo√£o Silva" (opcional)
}
```

**Response (200 OK):**
```json
{
  "documentoId": "550e8400-e29b-41d4-a716-446655440000",
  "pacienteId": "660e8400-e29b-41d4-a716-446655440001",
  "status": "processing",
  "message": "Documento recebido e em processamento"
}
```

**Response (202 Accepted):**
```json
{
  "documentoId": "550e8400-e29b-41d4-a716-446655440000",
  "status": "queued",
  "estimatedCompletionTime": "2026-01-29T15:30:00Z"
}
```

---

### **2. Status do Processamento**

#### `GET /api/exams/status/{documentoId}`

**Response (200 OK):**
```json
{
  "documentoId": "550e8400-e29b-41d4-a716-446655440000",
  "status": "completed",
  "processedAt": "2026-01-29T15:25:00Z",
  "examesExtraidos": 5,
  "erros": []
}
```

**Status poss√≠veis:**
- `pending` - Na fila
- `processing` - Em processamento
- `completed` - Conclu√≠do com sucesso
- `failed` - Falhou (ver campo `erros`)

---

### **3. Buscar Exames de um Paciente**

#### `GET /api/exams/paciente/{cpf}`

**Query Parameters:**
- `dataInicio` (opcional): yyyy-MM-dd
- `dataFim` (opcional): yyyy-MM-dd
- `tipoExame` (opcional): nome do tipo de exame

**Response (200 OK):**
```json
{
  "paciente": {
    "id": "660e8400-e29b-41d4-a716-446655440001",
    "nome": "Jo√£o Silva",
    "cpf": "12345678900",
    "dataNascimento": "1980-05-15"
  },
  "exames": [
    {
      "id": "770e8400-e29b-41d4-a716-446655440002",
      "tipo": "Lipidograma",
      "dataColeta": "2026-01-28",
      "documentoId": "550e8400-e29b-41d4-a716-446655440000",
      "resultados": [
        {
          "parametro": "Colesterol Total",
          "valor": 210,
          "unidade": "mg/dL",
          "referenciaMin": 0,
          "referenciaMax": 200,
          "status": "alto"
        },
        {
          "parametro": "HDL",
          "valor": 45,
          "unidade": "mg/dL",
          "referenciaMin": 40,
          "referenciaMax": 60,
          "status": "normal"
        }
      ]
    }
  ],
  "total": 1
}
```

---

### **4. Buscar Resultado Espec√≠fico**

#### `GET /api/exams/{exameId}`

**Response (200 OK):**
```json
{
  "id": "770e8400-e29b-41d4-a716-446655440002",
  "tipo": "Lipidograma",
  "dataColeta": "2026-01-28",
  "medicoSolicitante": "Dra. Maria Santos",
  "laboratorio": "Lab Central",
  "paciente": {
    "id": "660e8400-e29b-41d4-a716-446655440001",
    "nome": "Jo√£o Silva",
    "cpf": "12345678900"
  },
  "resultados": [
    {
      "id": "880e8400-e29b-41d4-a716-446655440003",
      "parametro": "Colesterol Total",
      "valorNumerico": 210,
      "unidade": "mg/dL",
      "referenciaMin": 0,
      "referenciaMax": 200,
      "status": "alto",
      "observacoes": null
    }
  ]
}
```

---

### **5. An√°lise Temporal (Tend√™ncias)**

#### `GET /api/exams/paciente/{cpf}/tendencia`

**Query Parameters:**
- `parametro`: nome do par√¢metro (ex: "Colesterol Total")
- `meses`: quantidade de meses retroativos (default: 12)

**Response (200 OK):**
```json
{
  "paciente": {
    "id": "660e8400-e29b-41d4-a716-446655440001",
    "nome": "Jo√£o Silva"
  },
  "parametro": "Colesterol Total",
  "unidade": "mg/dL",
  "referencia": {
    "min": 0,
    "max": 200
  },
  "serie": [
    {
      "data": "2025-07-15",
      "valor": 195,
      "status": "normal"
    },
    {
      "data": "2025-10-20",
      "valor": 205,
      "status": "alto"
    },
    {
      "data": "2026-01-28",
      "valor": 210,
      "status": "alto"
    }
  ],
  "tendencia": "crescente",
  "variacao": "+7.7%",
  "analise": "Colesterol em tend√™ncia crescente nos √∫ltimos 6 meses. Recomenda-se acompanhamento m√©dico."
}
```

---

### **6. Health Check**

#### `GET /api/health`

**Response (200 OK):**
```json
{
  "status": "healthy",
  "timestamp": "2026-01-29T15:30:00Z",
  "services": {
    "database": "healthy",
    "ollama": "healthy"
  },
  "version": "1.0.0"
}
```

---

## üõ†Ô∏è Tecnologias e Pacotes NuGet

### **Framework e Runtime**
- .NET 10 (ASP.NET Core)
- C# 13

### **Banco de Dados**
```bash
dotnet add package Npgsql.EntityFrameworkCore.PostgreSQL
dotnet add package Microsoft.EntityFrameworkCore.Design
dotnet add package Microsoft.EntityFrameworkCore.Tools
```

### **AI/LLM**
```bash
dotnet add package Microsoft.Extensions.AI --prerelease
dotnet add package Microsoft.Extensions.AI.Ollama --prerelease
```

### **Document Parsing**
```bash
# PDF
dotnet add package itext7

# Word
dotnet add package DocumentFormat.OpenXml

# Excel
dotnet add package EPPlus
```

### **Logging e Observabilidade**
```bash
dotnet add package Serilog.AspNetCore
dotnet add package Serilog.Sinks.Console
dotnet add package Serilog.Sinks.File
dotnet add package Serilog.Sinks.Seq
```

### **Valida√ß√£o**
```bash
dotnet add package FluentValidation.AspNetCore
```

### **Testes**
```bash
dotnet add package xUnit
dotnet add package Moq
dotnet add package FluentAssertions
dotnet add package Microsoft.AspNetCore.Mvc.Testing
dotnet add package Testcontainers
```

---

## üîÑ Pipeline de Processamento

```
1. Upload
   ‚Üì
2. Valida√ß√£o (tamanho, formato, duplicata)
   ‚Üì
3. Persist√™ncia (arquivo + metadados)
   ‚Üì
4. Identifica√ß√£o/Cria√ß√£o do Paciente
   ‚Üì
5. DocumentParserAgent (extrair texto)
   ‚Üì
6. ExtractionAgent (Ollama ‚Üí JSON)
   ‚Üì
7. ValidationAgent (validar dados)
   ‚Üì
8. NormalizationAgent (normalizar)
   ‚Üì
9. Persist√™ncia no PostgreSQL
   ‚Üì
10. Atualizar status do documento
```

### **Fluxo de Erro**
```
Erro em qualquer etapa
   ‚Üì
Registrar log detalhado
   ‚Üì
Atualizar documento.status = 'failed'
   ‚Üì
Salvar erro_processamento
   ‚Üì
Retornar 500 ou 422 (conforme caso)
```

---

## üìÖ Cronograma de Implementa√ß√£o

### **Sprint 1 - Setup e Infraestrutura (1 semana)**

**Dias 1-2:**
- [ ] Criar solution e projetos (.Api, .Application, .Domain, .Infrastructure)
- [ ] Setup PostgreSQL (Docker ou local)
- [ ] Configurar EF Core + Migrations
- [ ] Criar scripts SQL (tabelas, √≠ndices, triggers)
- [ ] Executar primeira migration

**Dias 3-4:**
- [ ] Implementar entidades do dom√≠nio (Paciente, Documento, Exame, etc.)
- [ ] Implementar AppDbContext
- [ ] Criar reposit√≥rios base (IExamRepository, ExamRepository)
- [ ] Testes unit√°rios das entidades

**Dias 5-7:**
- [ ] Verificar Ollama configurado localmente
- [ ] Testar conectividade (curl http://localhost:11434)
- [ ] Configurar appsettings.json (connection strings, Ollama)
- [ ] Implementar HealthController
- [ ] Implementar logging (Serilog)
- [ ] Documenta√ß√£o inicial

---

### **Sprint 2 - Document Parsing (1 semana)**

**Dias 1-3:**
- [ ] Implementar IDocumentParser interface
- [ ] Implementar PdfParser (iText7)
- [ ] Implementar WordParser (OpenXml)
- [ ] Implementar ExcelParser (EPPlus)
- [ ] Testes unit√°rios de cada parser

**Dias 4-5:**
- [ ] Implementar DocumentParserAgent
- [ ] Integrar parsers no agent
- [ ] Testes com 10 documentos reais (PDF, Word, Excel)
- [ ] Validar extra√ß√£o de texto

**Dias 6-7:**
- [ ] Implementar OcrAgent (para imagens, opcional v1)
- [ ] Tratamento de erros (arquivo corrompido, formato inv√°lido)
- [ ] Documentar limita√ß√µes

---

### **Sprint 3 - AI Extraction com Ollama (1,5 semanas)**

**Dias 1-2:**
- [ ] Verificar Ollama rodando (ollama list)
- [ ] Testar modelo manualmente (ollama run llama3.1:8b)
- [ ] Implementar health check do Ollama no .NET
- [ ] Configurar IChatClient no Program.cs

**Dias 3-5:**
- [ ] Implementar ExtractionAgent com Ollama
- [ ] Criar prompts estruturados (system + user)
- [ ] Integrar com IChatClient
- [ ] Parsing de JSON responses
- [ ] Tratamento de respostas malformadas
- [ ] Implementar retry logic

**Dias 6-8:**
- [ ] Implementar ValidationAgent
- [ ] Implementar NormalizationAgent
- [ ] Testes com 50 documentos reais
- [ ] Medir precis√£o e tempo de processamento
- [ ] Ajustar prompts baseado nos resultados

**Dias 9-10:**
- [ ] Implementar cache de respostas
- [ ] Implementar m√©tricas de performance (tokens/s, lat√™ncia)
- [ ] Documentar limita√ß√µes encontradas
- [ ] Implementar fallback para cloud (opcional)

---

### **Sprint 4 - API Endpoints (1 semana)**

**Dias 1-3:**
- [ ] Implementar POST /api/exams/upload
- [ ] Valida√ß√£o de entrada (tamanho, formato, CPF)
- [ ] Hash de documentos (evitar duplicatas)
- [ ] Persist√™ncia de Paciente + Documento
- [ ] Chamar pipeline de processamento
- [ ] Retornar 202 Accepted

**Dias 4-5:**
- [ ] Implementar GET /api/exams/status/{documentoId}
- [ ] Implementar GET /api/exams/paciente/{cpf}
- [ ] Filtros (data, tipo de exame)
- [ ] Pagina√ß√£o (se necess√°rio)

**Dias 6-7:**
- [ ] Implementar GET /api/exams/{exameId}
- [ ] Implementar endpoint de tend√™ncias (opcional v1)
- [ ] Testes de integra√ß√£o de todos endpoints
- [ ] Swagger/OpenAPI documentation

---

### **Sprint 5 - Testes e Refinamento (1 semana)**

**Dias 1-2:**
- [ ] Testes unit√°rios (cobertura >80%)
- [ ] Testes de integra√ß√£o (Testcontainers + PostgreSQL)
- [ ] Testes de carga (quantos docs/minuto?)

**Dias 3-4:**
- [ ] Refatora√ß√£o de c√≥digo
- [ ] Code review
- [ ] Corre√ß√£o de bugs identificados
- [ ] Otimiza√ß√£o de queries SQL

**Dias 5-7:**
- [ ] Documenta√ß√£o completa (README, API docs)
- [ ] Setup de CI/CD (opcional)
- [ ] Preparar ambiente de produ√ß√£o
- [ ] Deploy em staging

---

### **Sprint 6 - Deploy e Monitoramento (3 dias)**

**Dias 1-2:**
- [ ] Dockerfile + docker-compose
- [ ] Deploy em produ√ß√£o (ou staging final)
- [ ] Configurar logs centralizados (Seq, ELK, etc.)
- [ ] Configurar alertas (erros, lat√™ncia)

**Dia 3:**
- [ ] Valida√ß√£o final com usu√°rios
- [ ] Ajustes de √∫ltima hora
- [ ] Retrospectiva do projeto
- [ ] **Go Live! üöÄ**

---

## üìä M√©tricas de Sucesso

| M√©trica | Meta com Ollama Llama3.1:8b |
|---------|------------------------------|
| **Precis√£o de Extra√ß√£o** | >85% |
| **Tempo de Processamento** | <15s por documento |
| **Taxa de Sucesso** | >90% |
| **Custo por Documento** | $0 (local) |
| **Uptime** | >99% |
| **Cobertura de Testes** | >80% |

---

## üîê Seguran√ßa e Compliance

### **LGPD / Privacidade**
- ‚úÖ **Dados processados 100% localmente** (Ollama n√£o envia dados para fora)
- ‚úÖ Criptografia em tr√¢nsito (HTTPS)
- ‚úÖ Criptografia em repouso (PostgreSQL)
- ‚úÖ Logs n√£o cont√™m dados sens√≠veis (sanitiza√ß√£o)
- ‚úÖ **Compliance LGPD por design** (dados m√©dicos nunca saem do servidor)
- ‚ö†Ô∏è Implementar autentica√ß√£o/autoriza√ß√£o (v2)
- ‚ö†Ô∏è Auditoria de acessos (v2)

### **Valida√ß√µes**
- Tamanho m√°ximo de arquivo: 10MB
- Formatos permitidos: .pdf, .docx, .xlsx
- CPF validado (algoritmo)
- Rate limiting (v2)

---

## üê≥ Docker e Deploy

### **docker-compose.yml**

```yaml
version: '3.8'

services:
  api:
    build:
      context: .
      dockerfile: docker/Dockerfile
    ports:
      - "5000:8080"
    environment:
      - ASPNETCORE_ENVIRONMENT=Production
      - ConnectionStrings__DefaultConnection=Host=postgres;Database=medicalexams;Username=postgres;Password=postgres123
      - Ollama__Url=http://host.docker.internal:11434
      - Ollama__Model=llama3.1:8b
    depends_on:
      - postgres
    volumes:
      - ./uploads:/app/uploads
    extra_hosts:
      - "host.docker.internal:host-gateway"

  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres123
      POSTGRES_DB: medicalexams
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init.sql:/docker-entrypoint-initdb.d/init.sql

volumes:
  postgres_data:
```

**Nota:** Como o Ollama j√° est√° instalado localmente, a API se conecta via `host.docker.internal:11434`.

---

## üöÄ Pr√≥ximos Passos (v2)

### **Funcionalidades Futuras**

1. **Autentica√ß√£o e Autoriza√ß√£o**
   - JWT tokens
   - Roles (admin, m√©dico, paciente)
   - OAuth2 / OpenID Connect

2. **Dashboard Web**
   - Visualiza√ß√£o de exames
   - Gr√°ficos de tend√™ncias
   - Compara√ß√£o temporal
   - Exporta√ß√£o de relat√≥rios (PDF)

3. **Machine Learning**
   - Fine-tuning do modelo local
   - Classifica√ß√£o autom√°tica de exames
   - Detec√ß√£o de anomalias

4. **Integra√ß√µes**
   - HL7 / FHIR (sistemas hospitalares)
   - E-mail (alertas de valores cr√≠ticos)
   - WhatsApp (notifica√ß√µes)

5. **Performance**
   - Cache (Redis)
   - Processamento ass√≠ncrono (RabbitMQ/Kafka)
   - CDN para uploads

6. **Auditoria e Compliance**
   - Log de todos os acessos
   - Trilha de auditoria completa
   - Relat√≥rios de compliance LGPD

---

## üìö Refer√™ncias

- [Documenta√ß√£o .NET AI](https://learn.microsoft.com/dotnet/ai/)
- [Ollama Documentation](https://ollama.ai/docs)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)
- [EF Core Documentation](https://learn.microsoft.com/ef/core/)
- [iText7 Documentation](https://itextpdf.com/products/itext-7)

---

## ‚úÖ Checklist de Entrega

### **M√≠nimo Vi√°vel (MVP)**
- [ ] API REST funcionando
- [ ] Upload de PDF/Word/Excel
- [ ] **Ollama configurado e funcionando**
- [ ] **Extra√ß√£o com llama3.1:8b**
- [ ] Persist√™ncia em PostgreSQL
- [ ] Endpoints de consulta
- [ ] **Health check do Ollama**
- [ ] Testes (>70% cobertura)
- [ ] Documenta√ß√£o (README + Swagger)
- [ ] Docker Compose funcional

### **Desej√°vel**
- [ ] CI/CD pipeline
- [ ] Logging centralizado
- [ ] M√©tricas e observabilidade
- [ ] Health checks avan√ßados
- [ ] An√°lise de tend√™ncias

### **Futuro (v2)**
- [ ] Dashboard web
- [ ] Autentica√ß√£o completa
- [ ] Integra√ß√µes externas
- [ ] Fine-tuning do modelo

---

**√öltima atualiza√ß√£o:** 29/01/2026  
**Vers√£o:** 1.1 (com Ollama 3.1 local pr√©-configurado)  
**Status:** Pronto para kickoff üöÄ
