# üìù User Stories - Medical Exam Extractor API

**Projeto:** MedicalExamExtractor API  
**Data:** 29/01/2026  
**Vers√£o:** 1.0 (MVP Simplificado)  
**Autor:** Adjair Farias (com Clawdex üîç)

---

## üìå √âpicos

1. **Setup de Infraestrutura** - Configura√ß√£o inicial do projeto
2. **Parsing de Documentos** - Extra√ß√£o de texto de PDF/Word/Excel
3. **Extra√ß√£o com IA** - Usar Ollama para extrair dados estruturados
4. **Persist√™ncia de Dados** - Salvar no PostgreSQL
5. **API REST** - Endpoints para upload e consulta

---

## üéØ √âpico 1: Setup de Infraestrutura

### US-001: Criar estrutura do projeto .NET
**Como** desenvolvedor  
**Quero** criar a solution e projetos organizados por camadas  
**Para** ter uma arquitetura limpa e escal√°vel

**Crit√©rios de Aceita√ß√£o:**
- [ ] Solution criada com 4 projetos (Api, Application, Domain, Infrastructure)
- [ ] Refer√™ncias entre projetos configuradas
- [ ] .gitignore configurado
- [ ] README.md b√°sico criado

**Tarefas T√©cnicas:**
```bash
dotnet new sln -n MedicalExamExtractor
dotnet new webapi -n MedicalExamExtractor.Api
dotnet new classlib -n MedicalExamExtractor.Application
dotnet new classlib -n MedicalExamExtractor.Domain
dotnet new classlib -n MedicalExamExtractor.Infrastructure
dotnet sln add **/*.csproj
```

---

### US-002: Configurar banco PostgreSQL
**Como** desenvolvedor  
**Quero** ter um banco PostgreSQL rodando e configurado  
**Para** persistir os dados dos exames

**Crit√©rios de Aceita√ß√£o:**
- [ ] PostgreSQL rodando (Docker ou local)
- [ ] Database `medicalexams` criada
- [ ] Connection string configurada no appsettings.json
- [ ] EF Core configurado no projeto Infrastructure

**Tarefas T√©cnicas:**
```bash
# Docker
docker run --name postgres-medical \
  -e POSTGRES_USER=postgres \
  -e POSTGRES_PASSWORD=postgres123 \
  -e POSTGRES_DB=medicalexams \
  -p 5432:5432 \
  -d postgres:16-alpine

# Pacotes NuGet
dotnet add Infrastructure package Npgsql.EntityFrameworkCore.PostgreSQL
dotnet add Infrastructure package Microsoft.EntityFrameworkCore.Design
dotnet add Infrastructure package Microsoft.EntityFrameworkCore.Tools
```

---

### US-003: Criar modelo de dados e migrations
**Como** desenvolvedor  
**Quero** ter as tabelas do banco criadas via migrations  
**Para** garantir versionamento do schema

**Crit√©rios de Aceita√ß√£o:**
- [ ] Entidades criadas (Paciente, Documento, Exame, ResultadoExame, TipoExame)
- [ ] AppDbContext configurado
- [ ] Migration inicial criada e aplicada
- [ ] Seed de tipos_exame inserido

**Tarefas T√©cnicas:**
```bash
# Criar migration
dotnet ef migrations add InitialCreate --project Infrastructure --startup-project Api

# Aplicar migration
dotnet ef database update --project Infrastructure --startup-project Api
```

**Schema:**
- pacientes (id, nome, cpf, data_nascimento)
- documentos (id, paciente_id, nome_arquivo, tipo_arquivo, hash_sha256, status_processamento)
- tipos_exame (id, nome, categoria)
- exames (id, documento_id, tipo_exame_id, data_coleta, medico_solicitante)
- resultados_exame (id, exame_id, parametro, valor_numerico, unidade, referencia_min, referencia_max, status)

---

### US-004: Configurar integra√ß√£o com Ollama
**Como** desenvolvedor  
**Quero** integrar o Ollama no projeto .NET  
**Para** usar o LLM local na extra√ß√£o de dados

**Crit√©rios de Aceita√ß√£o:**
- [ ] Pacote Microsoft.Extensions.AI.Ollama instalado
- [ ] IChatClient configurado no Program.cs
- [ ] Ollama URL e modelo configurados no appsettings.json
- [ ] Health check endpoint criado (/health/ollama)
- [ ] Teste manual funcionando (curl para health check retorna 200)

**Tarefas T√©cnicas:**
```bash
dotnet add Api package Microsoft.Extensions.AI --prerelease
dotnet add Api package Microsoft.Extensions.AI.Ollama --prerelease
```

**appsettings.json:**
```json
{
  "Ollama": {
    "Url": "http://localhost:11434",
    "Model": "llama3.1:8b",
    "Temperature": 0.1,
    "MaxTokens": 4096
  }
}
```

---

## üéØ √âpico 2: Parsing de Documentos

### US-005: Implementar parser de PDF
**Como** sistema  
**Quero** extrair texto de arquivos PDF  
**Para** enviar para o LLM processar

**Crit√©rios de Aceita√ß√£o:**
- [ ] Classe PdfParser implementada
- [ ] Extra√ß√£o de texto funcionando para PDFs simples (n√£o escaneados)
- [ ] Tratamento de erro para PDFs corrompidos
- [ ] Teste manual com 3 PDFs reais

**Tarefas T√©cnicas:**
```bash
dotnet add Infrastructure package itext7
```

**Interface:**
```csharp
public interface IDocumentParser
{
    Task<string> ExtractTextAsync(Stream fileStream, string fileType);
}
```

---

### US-006: Implementar parser de Word
**Como** sistema  
**Quero** extrair texto de arquivos .docx  
**Para** enviar para o LLM processar

**Crit√©rios de Aceita√ß√£o:**
- [ ] Classe WordParser implementada
- [ ] Extra√ß√£o de texto funcionando
- [ ] Tratamento de erro para arquivos corrompidos
- [ ] Teste manual com 3 documentos Word reais

**Tarefas T√©cnicas:**
```bash
dotnet add Infrastructure package DocumentFormat.OpenXml
```

---

### US-007: Implementar parser de Excel
**Como** sistema  
**Quero** extrair texto de arquivos .xlsx  
**Para** enviar para o LLM processar

**Crit√©rios de Aceita√ß√£o:**
- [ ] Classe ExcelParser implementada
- [ ] Extra√ß√£o de todas as c√©lulas (formato tabular)
- [ ] Tratamento de erro para arquivos corrompidos
- [ ] Teste manual com 3 planilhas reais

**Tarefas T√©cnicas:**
```bash
dotnet add Infrastructure package EPPlus
```

---

### US-008: Criar DocumentParserAgent
**Como** sistema  
**Quero** ter um agent que decide qual parser usar  
**Para** abstrair a l√≥gica de parsing

**Crit√©rios de Aceita√ß√£o:**
- [ ] DocumentParserAgent implementado
- [ ] Detecta tipo de arquivo pela extens√£o
- [ ] Chama o parser correto (PDF/Word/Excel)
- [ ] Retorna texto bruto extra√≠do
- [ ] Lan√ßa exce√ß√£o para formatos n√£o suportados

**Fluxo:**
```
Stream + extens√£o ‚Üí DocumentParserAgent ‚Üí Parser espec√≠fico ‚Üí Texto
```

---

## üéØ √âpico 3: Extra√ß√£o com IA

### US-009: Implementar ExtractionAgent com Ollama
**Como** sistema  
**Quero** enviar texto para o Ollama e receber JSON estruturado  
**Para** extrair dados dos exames

**Crit√©rios de Aceita√ß√£o:**
- [ ] ExtractionAgent implementado
- [ ] System prompt otimizado para exames m√©dicos
- [ ] User prompt com texto do documento
- [ ] Parsing de resposta JSON do LLM
- [ ] Tratamento de resposta malformada (retry 1x)
- [ ] Teste com 10 documentos reais, medir precis√£o

**Estrutura JSON esperada:**
```json
{
  "paciente": {
    "nome": "Jo√£o Silva",
    "data_nascimento": "1980-05-15",
    "data_coleta": "2026-01-28",
    "medico_solicitante": "Dra. Maria"
  },
  "exames": [
    {
      "tipo": "Colesterol Total",
      "valor": 210,
      "unidade": "mg/dL",
      "referencia_min": 0,
      "referencia_max": 200,
      "status": "alto",
      "observacoes": null
    }
  ]
}
```

**Meta de Precis√£o:** >85%

---

### US-010: Implementar ValidationAgent
**Como** sistema  
**Quero** validar os dados extra√≠dos pelo LLM  
**Para** garantir consist√™ncia antes de salvar

**Crit√©rios de Aceita√ß√£o:**
- [ ] ValidationAgent implementado
- [ ] Valida√ß√µes b√°sicas:
  - Valor num√©rico √© realmente n√∫mero
  - Status √© um dos permitidos (normal, baixo, alto, cr√≠tico)
  - Unidade n√£o est√° vazia
  - CPF v√°lido (se presente)
- [ ] Retorna lista de warnings (n√£o bloqueia)
- [ ] Logs de valida√ß√£o

---

### US-011: Implementar NormalizationAgent
**Como** sistema  
**Quero** normalizar os dados extra√≠dos  
**Para** padronizar nomenclatura e unidades

**Crit√©rios de Aceita√ß√£o:**
- [ ] NormalizationAgent implementado
- [ ] Normaliza√ß√£o de nomes de exames:
  - "Col. Total" ‚Üí "Colesterol Total"
  - "Glicemia Jejum" ‚Üí "Glicemia em Jejum"
  - "TGO" ‚Üí "TGO (AST)"
- [ ] Mapeamento para tipos_exame (lookup na tabela)
- [ ] Convers√£o de unidades (opcional MVP)

---

### US-012: Implementar MedicalExamPipeline (Orquestrador)
**Como** sistema  
**Quero** orquestrar todos os agents em sequ√™ncia  
**Para** processar um documento do in√≠cio ao fim

**Crit√©rios de Aceita√ß√£o:**
- [ ] MedicalExamPipeline implementado
- [ ] Fluxo completo funcional:
  1. DocumentParserAgent (texto bruto)
  2. ExtractionAgent (JSON estruturado)
  3. ValidationAgent (verificar dados)
  4. NormalizationAgent (padronizar)
  5. Retornar ExamResult
- [ ] Logs em cada etapa
- [ ] Tratamento de erro (para pipeline em qualquer etapa)

**Interface:**
```csharp
public class MedicalExamPipeline
{
    public async Task<ExamResult> ProcessAsync(
        Stream fileStream, 
        string fileType,
        CancellationToken ct = default);
}
```

---

## üéØ √âpico 4: Persist√™ncia de Dados

### US-013: Implementar reposit√≥rio de dados
**Como** sistema  
**Quero** salvar dados extra√≠dos no PostgreSQL  
**Para** persistir hist√≥rico de exames

**Crit√©rios de Aceita√ß√£o:**
- [ ] ExamRepository implementado
- [ ] M√©todos:
  - SaveExamAsync(ExamResult, documentId)
  - GetExamsByPacienteAsync(cpf, filtros)
  - GetExamByIdAsync(exameId)
- [ ] Transa√ß√µes (salvar paciente + documento + exames atomicamente)
- [ ] Tratamento de CPF duplicado (buscar paciente existente)

---

### US-014: Implementar hash de documentos
**Como** sistema  
**Quero** detectar documentos duplicados via SHA256  
**Para** evitar reprocessamento

**Crit√©rios de Aceita√ß√£o:**
- [ ] Calcular SHA256 do arquivo no upload
- [ ] Verificar se hash j√° existe na tabela documentos
- [ ] Se existe, retornar resultado anterior (sem reprocessar)
- [ ] Se n√£o existe, prosseguir com pipeline

---

## üéØ √âpico 5: API REST

### US-015: Implementar endpoint de upload
**Como** usu√°rio da API  
**Quero** fazer upload de um documento m√©dico  
**Para** extrair dados automaticamente

**Endpoint:** `POST /api/exams/upload`

**Crit√©rios de Aceita√ß√£o:**
- [ ] Recebe IFormFile (multipart/form-data)
- [ ] Recebe CPF do paciente (obrigat√≥rio)
- [ ] Recebe nome do paciente (opcional)
- [ ] Valida√ß√µes:
  - Arquivo n√£o vazio
  - Tamanho m√°x 10MB
  - Extens√£o v√°lida (.pdf, .docx, .xlsx)
  - CPF v√°lido
- [ ] Salva documento na tabela com status "processing"
- [ ] Chama pipeline ass√≠ncrono
- [ ] Retorna 202 Accepted com documentoId
- [ ] Em caso de sucesso, atualiza status para "completed"
- [ ] Em caso de erro, atualiza status para "failed" + erro_processamento

**Request:**
```http
POST /api/exams/upload
Content-Type: multipart/form-data

file: [binary]
cpf: 12345678900
nomePaciente: Jo√£o Silva
```

**Response (202):**
```json
{
  "documentoId": "550e8400-e29b-41d4-a716-446655440000",
  "pacienteId": "660e8400-e29b-41d4-a716-446655440001",
  "status": "processing"
}
```

---

### US-016: Implementar endpoint de status
**Como** usu√°rio da API  
**Quero** consultar o status de processamento de um documento  
**Para** saber se j√° foi conclu√≠do

**Endpoint:** `GET /api/exams/status/{documentoId}`

**Crit√©rios de Aceita√ß√£o:**
- [ ] Busca documento por ID
- [ ] Retorna status atual (pending, processing, completed, failed)
- [ ] Se completed, retorna quantidade de exames extra√≠dos
- [ ] Se failed, retorna mensagem de erro
- [ ] Retorna 404 se documento n√£o existe

**Response (200):**
```json
{
  "documentoId": "550e8400-e29b-41d4-a716-446655440000",
  "status": "completed",
  "processedAt": "2026-01-29T15:25:00Z",
  "examesExtraidos": 5,
  "erros": []
}
```

---

### US-017: Implementar endpoint de consulta por paciente
**Como** usu√°rio da API  
**Quero** buscar todos os exames de um paciente pelo CPF  
**Para** visualizar hist√≥rico m√©dico

**Endpoint:** `GET /api/exams/paciente/{cpf}`

**Crit√©rios de Aceita√ß√£o:**
- [ ] Busca paciente por CPF
- [ ] Retorna lista de exames com resultados
- [ ] Suporta filtros opcionais:
  - dataInicio (yyyy-MM-dd)
  - dataFim (yyyy-MM-dd)
  - tipoExame (nome)
- [ ] Retorna 404 se paciente n√£o existe
- [ ] Retorna 200 com array vazio se n√£o tem exames

**Response (200):**
```json
{
  "paciente": {
    "id": "660e8400-e29b-41d4-a716-446655440001",
    "nome": "Jo√£o Silva",
    "cpf": "12345678900",
    "dataNascimento": "1980-05-15"
  },
  "exames": [
    {
      "id": "770e8400-e29b-41d4-a716-446655440002",
      "tipo": "Lipidograma",
      "dataColeta": "2026-01-28",
      "resultados": [
        {
          "parametro": "Colesterol Total",
          "valor": 210,
          "unidade": "mg/dL",
          "status": "alto"
        }
      ]
    }
  ],
  "total": 1
}
```

---

### US-018: Implementar endpoint de consulta por exame
**Como** usu√°rio da API  
**Quero** buscar detalhes de um exame espec√≠fico  
**Para** ver todos os resultados

**Endpoint:** `GET /api/exams/{exameId}`

**Crit√©rios de Aceita√ß√£o:**
- [ ] Busca exame por ID
- [ ] Retorna dados do paciente
- [ ] Retorna todos os resultados do exame
- [ ] Retorna 404 se exame n√£o existe

**Response (200):**
```json
{
  "id": "770e8400-e29b-41d4-a716-446655440002",
  "tipo": "Lipidograma",
  "dataColeta": "2026-01-28",
  "medicoSolicitante": "Dra. Maria Santos",
  "paciente": {
    "id": "660e8400-e29b-41d4-a716-446655440001",
    "nome": "Jo√£o Silva",
    "cpf": "12345678900"
  },
  "resultados": [
    {
      "id": "880e8400-e29b-41d4-a716-446655440003",
      "parametro": "Colesterol Total",
      "valorNumerico": 210,
      "unidade": "mg/dL",
      "referenciaMin": 0,
      "referenciaMax": 200,
      "status": "alto"
    }
  ]
}
```

---

### US-019: Implementar health checks
**Como** operador  
**Quero** verificar a sa√∫de da API  
**Para** monitorar disponibilidade

**Endpoints:**
- `GET /health` - Health geral
- `GET /health/ollama` - Health do Ollama
- `GET /health/database` - Health do PostgreSQL

**Crit√©rios de Aceita√ß√£o:**
- [ ] /health retorna 200 se tudo OK
- [ ] /health/ollama testa conex√£o com Ollama (ping)
- [ ] /health/database testa conex√£o com PostgreSQL
- [ ] Retorna 503 Service Unavailable se algum servi√ßo est√° down

**Response (200):**
```json
{
  "status": "healthy",
  "timestamp": "2026-01-29T15:30:00Z",
  "services": {
    "database": "healthy",
    "ollama": "healthy"
  }
}
```

---

### US-020: Configurar Swagger/OpenAPI
**Como** desenvolvedor  
**Quero** ter documenta√ß√£o autom√°tica da API  
**Para** facilitar uso e testes

**Crit√©rios de Aceita√ß√£o:**
- [ ] Swagger configurado no Program.cs
- [ ] Dispon√≠vel em /swagger
- [ ] Todos os endpoints documentados
- [ ] Exemplos de request/response
- [ ] Descri√ß√µes dos par√¢metros

---

## üéØ √âpico 6: Deploy e Documenta√ß√£o

### US-021: Criar Dockerfile
**Como** DevOps  
**Quero** containerizar a aplica√ß√£o  
**Para** facilitar deploy

**Crit√©rios de Aceita√ß√£o:**
- [ ] Dockerfile criado (multi-stage build)
- [ ] Imagem build com sucesso
- [ ] Container roda com sucesso
- [ ] Vari√°veis de ambiente configur√°veis

**Dockerfile:**
```dockerfile
FROM mcr.microsoft.com/dotnet/aspnet:10.0 AS base
WORKDIR /app
EXPOSE 8080

FROM mcr.microsoft.com/dotnet/sdk:10.0 AS build
WORKDIR /src
COPY . .
RUN dotnet restore
RUN dotnet build -c Release -o /app/build

FROM build AS publish
RUN dotnet publish -c Release -o /app/publish

FROM base AS final
WORKDIR /app
COPY --from=publish /app/publish .
ENTRYPOINT ["dotnet", "MedicalExamExtractor.Api.dll"]
```

---

### US-022: Criar docker-compose
**Como** DevOps  
**Quero** subir API + PostgreSQL com um comando  
**Para** simplificar ambiente de desenvolvimento

**Crit√©rios de Aceita√ß√£o:**
- [ ] docker-compose.yml criado
- [ ] Servi√ßos: api + postgres
- [ ] API conecta no Ollama local (host.docker.internal)
- [ ] API conecta no PostgreSQL do container
- [ ] Volumes persistentes para PostgreSQL
- [ ] `docker-compose up -d` funciona

---

### US-023: Criar documenta√ß√£o do projeto
**Como** desenvolvedor  
**Quero** ter documenta√ß√£o clara do projeto  
**Para** onboarding e manuten√ß√£o

**Crit√©rios de Aceita√ß√£o:**
- [ ] README.md completo:
  - Descri√ß√£o do projeto
  - Pr√©-requisitos (Ollama, PostgreSQL)
  - Como rodar localmente
  - Como rodar com Docker
  - Exemplos de uso (curl)
  - Estrutura do projeto
- [ ] SETUP.md com instru√ß√µes detalhadas
- [ ] Coment√°rios no c√≥digo (classes principais)

---

## üìä Resumo de Prioridades

### **Sprint 1 (1 semana) - Funda√ß√£o**
- US-001: Criar estrutura do projeto
- US-002: Configurar PostgreSQL
- US-003: Criar modelo de dados
- US-004: Configurar Ollama

### **Sprint 2 (1 semana) - Parsing**
- US-005: Parser PDF
- US-006: Parser Word
- US-007: Parser Excel
- US-008: DocumentParserAgent

### **Sprint 3 (1,5 semanas) - IA**
- US-009: ExtractionAgent
- US-010: ValidationAgent
- US-011: NormalizationAgent
- US-012: MedicalExamPipeline

### **Sprint 4 (1 semana) - Persist√™ncia**
- US-013: Reposit√≥rio
- US-014: Hash de documentos

### **Sprint 5 (1 semana) - API**
- US-015: Endpoint upload
- US-016: Endpoint status
- US-017: Endpoint consulta por paciente
- US-018: Endpoint consulta por exame
- US-019: Health checks
- US-020: Swagger

### **Sprint 6 (3 dias) - Deploy**
- US-021: Dockerfile
- US-022: Docker Compose
- US-023: Documenta√ß√£o

---

## üìã Backlog (Fora do MVP)

### **Funcionalidades Futuras**
- Autentica√ß√£o JWT
- Processamento ass√≠ncrono (background jobs)
- Cache de respostas
- An√°lise de tend√™ncias temporais
- Dashboard web
- Exporta√ß√£o de relat√≥rios PDF
- OCR para documentos escaneados
- Fine-tuning do modelo local
- Integra√ß√£o HL7/FHIR

---

## ‚úÖ Definition of Done (DoD)

Uma User Story est√° **DONE** quando:

1. ‚úÖ C√≥digo implementado e funcionando
2. ‚úÖ Testado manualmente (smoke test)
3. ‚úÖ Code review feito (se trabalho em equipe)
4. ‚úÖ Merged na branch main/develop
5. ‚úÖ Documenta√ß√£o atualizada (se aplic√°vel)
6. ‚úÖ Funcionando no ambiente local

**N√£o inclu√≠do no MVP:**
- ‚ùå Testes unit√°rios
- ‚ùå Testes de integra√ß√£o
- ‚ùå Testes de carga
- ‚ùå Deploy em produ√ß√£o

---

**√öltima atualiza√ß√£o:** 29/01/2026  
**Vers√£o:** 1.0 (MVP Simplificado)  
**Total de User Stories:** 23
